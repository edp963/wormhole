input{
  file{
    path => ["/data1/hadoop/yarn/log/application_*/container_*/stderr","/data2/hadoop/yarn/log/application_*/container_*/stderr"]
    type => "sparkErrorLogs"
  }

  file{
    path => ["/data1/hadoop/yarn/log/application_*/container_*/stdout","/data2/hadoop/yarn/log/application_*/container_*/stdout"]
    type => "sparkLogs"
  }

}

filter{
  grok{ match => { "path" => "(?<appId>application\w*\b)"}}
  grok{ match => { "path" => "(?<container>container\w*\b)"}}

  if [loglevel] == "INFO" { drop{ percentage => 80 } }
  if [loglevel] == "DEBUG" { drop {}}

  if [type] == "sparkErrorLogs" {
    grok{ match => {"message" => "%{DATESTAMP:ums_ts_} %{LOGLEVEL:loglevel} %{USERNAME:className}"} }
  }

  if [type] == "sparkLogs" {
    grok{ match => {"message" => "%{TIMESTAMP_ISO8601:ums_ts_} \[%{GREEDYDATA:taskInfo}\] %{LOGLEVEL:loglevel}  %{USERNAME:className}"} }
  }

}

output{
  kafka{
    topic_id => "logstash-output"
    bootstrap_servers => "10.120.65.146:9092"
    codec => json{}
  }

  stdout{codec=>rubydebug}
}